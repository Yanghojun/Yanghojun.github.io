---
layout: article
title:  "Android 상황 별 해결 방법"
category: [Android]
tag: [안드로이드, 버그, 해결]
permalink: /AndroidSolvingMethod/
show_author_profile: true
aside:
    toc: true
    toc_sticky: true
toc_sticky: true
sidebar:
    nav: "study-nav"
---

# 핸드폰, android studio 연동 문제

1. 디버깅 모드 되어있는지 Check
2. USB 옵션이 "파일 선택"으로 되어있는지 Check
3. 삼성 통합 usb 드라이버 설치

# Connection refused: connect 문제

안드로이드 디바이스를 물리적으로 컴퓨터와 연결해서 디버깅을 진행하려는데 연결이 되었음에도 App install, launching이 제대로 되지 않았음.  
또한 `Adb connection Error: 현재 연결은 원격 호스트에 의해 강제로 끊겼습니다.` 라는 말이 계속 아래 상태창에 출력됨.

아래와 같은 방법으로 해결

```bash
안드로이드 studio에서
File -> setting -> Build, Execution, Deployment -> Debugger -> "Enable adb mDNS for wireless debugging" 해제
```

# Android Pytorch

## DeepLabV3

타이어 세그멘테이션 작업을 진행하기 위해 오픈소스를 실행하는데 ptl 파일(weight 파일)을 제대로 load 하지 못하는 문제가 발생하였다. (facebook ~~, bytecode.pkl error 등 발생)
```python
import torch
from torch.utils.mobile_optimizer import optimize_for_mobile

model = torch.hub.load('pytorch/vision:v0.11.0', 'deeplabv3_resnet50', pretrained=True)
model.eval()

scripted_module = torch.jit.script(model)
optimized_scripted_module = optimize_for_mobile(scripted_module)

# Export full jit version model (not compatible with lite interpreter)
scripted_module.save("deeplabv3_scripted.pt")
# Export lite interpreter version model (compatible with lite interpreter)
scripted_module._save_for_lite_interpreter("deeplabv3_scripted.ptl")
# using optimized lite interpreter model makes inference about 60% faster than the non-optimized lite interpreter model, which is about 6% faster than the non-optimized full jit model
optimized_scripted_module._save_for_lite_interpreter("deeplabv3_scripted_optimized.ptl")
```

깃헙 저장소에 있는 코드는 위와 같았으며   `torch.hub.load('pytorch/vision:v0.7.0', 'deeplabv3_resnet50', pretrained=True)`로 버젼을 낮추어서 진행하니 문제없이 작동되었다. 현재 내 torch 버젼이 0.10이여서 발생했던 문제일 수도 있을 법 하다.